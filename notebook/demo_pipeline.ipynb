{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e61853b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.document_loaders import ArxivLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "from langgraph.graph import StateGraph, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b20e8fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rathi\\AppData\\Local\\Temp\\ipykernel_20340\\2320363549.py:1: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=\"gemma:2b\")  # for summaries, comparisons\n",
      "C:\\Users\\rathi\\AppData\\Local\\Temp\\ipykernel_20340\\2320363549.py:2: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")  # fast embeddings\n"
     ]
    }
   ],
   "source": [
    "llm = Ollama(model=\"gemma:2b\")  # for summaries, comparisons\n",
    "embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")  # fast embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c04100fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"transformer models in healthcare\"\n",
    "loader = ArxivLoader(query=query, max_docs=2)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd1da96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Chroma.from_documents(docs, embeddings, persist_directory=\"chroma_db\")\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07e7c0bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rathi\\AppData\\Local\\Temp\\ipykernel_20340\\1424376213.py:19: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  results = retriever.get_relevant_documents(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“‘ Literature Review Draft:\n",
      "\n",
      "## Literature Review Draft\n",
      "\n",
      "**Review of Comparison of Research Summaries**\n",
      "\n",
      "The two research summaries offer valuable insights into the strategic importance of data governance, strategic competitive advantages, and the transformative potential of healthcare-specific foundation models. Despite their differing focuses, both summaries highlight the challenges faced by healthcare organizations in managing fragmented data structures, lack of data governance frameworks, and stringent data privacy regulations.\n",
      "\n",
      "While the first summary provides a general overview of the strategic imperative for healthcare organizations to develop proprietary foundation models, the second summary focuses on the application of transformer-based models in intra-operative anesthesia management data. This difference in scope enables the second summary to delve into the specific performance of these models, offering valuable insights into their potential benefits and challenges.\n",
      "\n",
      "Furthermore, the first summary provides a broader overview of the potential benefits and challenges associated with proprietary foundation models, while the second summary offers a more detailed description of the specific application of transformer-based models. This allows for a deeper understanding of the technology's potential impact on healthcare delivery.\n",
      "\n",
      "**Key Points of Comparison:**\n",
      "\n",
      "| Feature | First Summary | Second Summary |\n",
      "|---|---|---|\n",
      "| Scope | Strategic imperative for data governance and proprietary foundation models | Application of transformer-based models in intra-operative anesthesia management |\n",
      "| Focus | Challenges and opportunities associated with proprietary foundation models | Performance of transformer-based models |\n",
      "| Detail | Broader overview of potential benefits and challenges | More detailed description of specific application |\n",
      "\n",
      "**Conclusion:**\n",
      "\n",
      "The comparison between these two research summaries provides valuable insights into the strategic importance of data governance, the challenges and opportunities associated with proprietary foundation models, and the potential impact of transformer-based models on healthcare delivery. These summaries offer a starting point for further research and provide valuable recommendations for healthcare organizations looking to leverage data governance and advanced technologies to improve patient outcomes and reduce costs.\n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict, List\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# -------------------------\n",
    "# 1. Define State Schema\n",
    "# -------------------------\n",
    "class GraphState(TypedDict, total=False):\n",
    "    query: str\n",
    "    papers: List[str]\n",
    "    summaries: List[str]\n",
    "    comparison: str\n",
    "    literature_review: str\n",
    "\n",
    "# -------------------------\n",
    "# 2. Define Agents\n",
    "# -------------------------\n",
    "def retriever_agent(state: GraphState) -> GraphState:\n",
    "    query = state[\"query\"]\n",
    "    results = retriever.get_relevant_documents(query)\n",
    "    return {\"papers\": results}\n",
    "\n",
    "def summarizer_agent(state: GraphState) -> GraphState:\n",
    "    summaries = []\n",
    "    for doc in state[\"papers\"]:\n",
    "        prompt = f\"Summarize this paper in 4 sections: Background, Methods, Results, Conclusion.\\n\\n{doc.page_content[:2000]}\"\n",
    "        summary = llm.invoke(prompt)\n",
    "        summaries.append(summary)\n",
    "    return {\"summaries\": summaries}\n",
    "\n",
    "def comparator_agent(state: GraphState) -> GraphState:\n",
    "    prompt = f\"Compare these research summaries and highlight similarities & differences:\\n\\n{state['summaries']}\"\n",
    "    comparison = llm.invoke(prompt)\n",
    "    return {\"comparison\": comparison}\n",
    "\n",
    "def synthesizer_agent(state: GraphState) -> GraphState:\n",
    "    prompt = f\"Write a short literature review draft based on the following comparison:\\n\\n{state['comparison']}\"\n",
    "    lit_review = llm.invoke(prompt)\n",
    "    return {\"literature_review\": lit_review}\n",
    "\n",
    "# -------------------------\n",
    "# 3. Build Graph\n",
    "# -------------------------\n",
    "graph = StateGraph(GraphState)\n",
    "\n",
    "graph.add_node(\"retriever\", retriever_agent)\n",
    "graph.add_node(\"summarizer\", summarizer_agent)\n",
    "graph.add_node(\"comparator\", comparator_agent)\n",
    "graph.add_node(\"synthesizer\", synthesizer_agent)\n",
    "\n",
    "graph.add_edge(\"retriever\", \"summarizer\")\n",
    "graph.add_edge(\"summarizer\", \"comparator\")\n",
    "graph.add_edge(\"comparator\", \"synthesizer\")\n",
    "graph.add_edge(\"synthesizer\", END)\n",
    "\n",
    "graph.set_entry_point(\"retriever\")\n",
    "\n",
    "app = graph.compile()\n",
    "\n",
    "# -------------------------\n",
    "# 4. Run Workflow\n",
    "# -------------------------\n",
    "output = app.invoke({\"query\": \"transformer models in healthcare\"})\n",
    "print(\"\\nðŸ“‘ Literature Review Draft:\\n\")\n",
    "print(output[\"literature_review\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cb30a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LangChain1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
